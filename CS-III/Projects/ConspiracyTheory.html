<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8">
    <title> Conspiracy Theory </title>
    <link rel="stylesheet" href="../../mystyle.css">
  </head>
  <ul>
    <li><a href="../../index.html">Home</a></li>
    <li class="dropdown">
      <a href="javascript:void(0)" class="dropbtn"> Info</a>
      <div class="dropdown-content">
	<a href="../../AboutMe.html">About Me</a>
	<a href="../../ImportantToMe.html"> Why this is important for me </a>
	<a href="../../2021-2022ISP.html"> 2021-2022 ISP </a>
	<a href="../../Classes.html"> My Classes </a>
      </div>
    </li>

    <li class="dropdown">
      <a href="javascript:void(0)" class="dropbtn">Essays</a>
      <div class="dropdown-content">
	<a href="Fingerprints.html">Fingerprints</a>
	<a href="AI%20Sentience.html">AI Sentience</a>
      </div>
    </li>
    <li> <a href="https://isaacdaking.github.io"> My Github Page </a></li>
    <li class="dropdown">
      <a href="javascript:void(0)" class="dropbtn">Projects</a>
      <div class="dropdown-content">
	<a href="../Projects/Optimal%20Sort.html">Optimal Sort </a>
      </div>
    </li>
      </ul>
  <h2 class="centertxt">AI Sentience Essay</h2>
  <p class="centertxt">
    Isaac Pandyan
    <br>
    <br>
    Allen High School STEAM Center
    <br>
    <br>
    Advanced Computer Science II
    <br>
    <br>
    Mr. Ben-Yaakov
    <br>
    <br>
    October 19, 2023
    <br>
  <p class="demopara">
    <b>The Basics of Recommendation Algorithms</b>
    <br>
    <br>
    Recommendation algorithms are a type of software system that offers personalized suggestions to users, finding them content best suited for them, whether that be in the form of general content or advertisements. There are many types of these algorithms, with collaborative filtering and content-based filtering being among the most prominent (as of now). These algorithms most commonly use user-based filtering, which suggests items based on similar users' preferences, and item-based filtering which suggests items similar to a user's previous interactions. All these algorithms are usually built on an interaction/retention tracking system that figures out what people like based on how long they spend on it, if they like it, if they comment on it, and if they share it to others. These algorithms are usually spread throughout as many contexts as possible in order to maximize data collected and parsed with the end goal being to sharpen the algorithms accuracy (this can be achieved through the recommendation algorithm being cross-platform, for example, Google Adsense operating on both Youtube and independent webpages). 
    <br>
    <br>
    <b>The Feedback Loop</b>
    <br>
    <br>
    The Feedback Loop is an easily explained concept as it is simply a natural consequence of both how the human brain works and how algorithms are designed with how the human brain works in mind. Humans, on average, do not like being met with opposing opinions, this can be observed by how even traditional media, oftentimes seen as a remnant of the pre-digital age, splits itself along party lines, when one newspaper will support one ideology the other will support the opposing ideology (the same can be said for cable news and radio). Just as this applies to traditional media, it applies to social media as well, and it does this through the feedback loop. As a human spends time on a platform, they feel more comfortable watching content that reinforces their own worldview and the recommendation algorithm will take notice. After a while, the recommendation algorithm may stop recommending opposing views altogether, eventually creating an “echo chamber” . When an echochamber is created the members of the echo chamber will oftentimes sub-consciously radicalize one another as they inherently are not being exposed to opposing views that push against the popular narrative of echo chamber by nature of being in an echo chamber in the first place. This process of digital community isolation and self-radicalization can eventually lead to real life extremist violence, such as in the case of the Allen Outlet Mall Shooter and countless other examples.
    <br>
    <br>
    <b>Conspiracy Theories & Algorithmic Amplification </b>
    <br>
    <br>
    Worryingly, Recommendation algorithms have the potential to propagate conspiracy theories, as the algorithms are designed to provide individuals with the exact content they want (using the methods previously described). Therefore, the algorithms have the unintended consequence of finding people who are most vulnerable to be consumed by conspiracy theories, such as those common in the anti-vaccination movement for example, and giving them said conspiracy theories, likely packaged with a sensationalist hook in the form of a video title or article headline which is designed to create as many interactions as possible in order to play into the recommendation algorithm’s interaction/retention tracking system. This, paired with the feedback loop previously discussed, creates an environment where sensationalist far-fetched ideas are propagated and rarely challenged. 
      <br>
      <br>
      <b>Platform Incentives</b>
      <br>
      <br>
As briefly mentioned before, platforms will oftentimes incentivize the creation of sensationalist content with the hope of increasing both retention and user interaction in order to sell a large number of high-value ads. This is because, for systems such as that of Youtube or Meta, The longer you stay on the platform, the more advertisements can be served to you on average. In addition, the more users that on average interact with content, the more the platform is able to charge for advertisement space. These platforms are designed to make a profit, so it makes sense that their algorithms view profit as the priority. However, an unintended consequence of this seems to be this promotion of poorly fact-checked sensationalist content. As individuals figure out the type of content that the algorithm promotes, it makes sense that many would begin producing content designed specifically with the algorithm favored content traits in mind in order to gain popularity on the platform, therefore incentivizing an increase in the quantity of sensationalist content as well.
<br>      
<br>
      <b>Potential for Exploitation</b>
      <br>
      <br>
The potential for exploitation of recommendation algorithms comes from bad-faith actors who know all of the previously discussed weaknesses and features of the algorithms and use them to either enrich themselves or propagate their own ideology. As discussed before, platforms will often mistakenly create recommendation algorithms that demand retention and interaction in order for content to be pushed throughout the platform, and oftentimes the content that is the most polarizing is the content that has the most interactions and retention. Due to this, polarizing content will be pushed to people who the algorithm knows are most likely to be vulnerable (despite that obviously not being the explicit intention). Bad-faith actors would do this most likely for money offered by the platform in exchange for creating content (regardless of quality), in order propagating their own ideology (regardless of how detached from reality their ideology is), or simply for the modern fame provided by social media platforms.
<br>      
<br>

  </p>
  </body>
  </html>
